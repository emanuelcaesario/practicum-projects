{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# Developing a Prepaid Package Classification Model for Megaline Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1-Project-Description\" data-toc-modified-id=\"1-Project-Description-1\">1 Project Description</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Objective\" data-toc-modified-id=\"1.1-Objective-1.1\">1.1 Objective</a></span></li><li><span><a href=\"#1.2-Stages-of-Project-Completion\" data-toc-modified-id=\"1.2-Stages-of-Project-Completion-1.2\">1.2 Stages of Project Completion</a></span></li></ul></li><li><span><a href=\"#2-Data-Description\" data-toc-modified-id=\"2-Data-Description-2\">2 Data Description</a></span></li><li><span><a href=\"#3-Creating-a-Classification-Model\" data-toc-modified-id=\"3-Creating-a-Classification-Model-3\">3 Creating a Classification Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Import-All-Libraries\" data-toc-modified-id=\"3.1-Import-All-Libraries-3.1\">3.1 Import All Libraries</a></span></li><li><span><a href=\"#3.2-Open-and-Read-Data\" data-toc-modified-id=\"3.2-Open-and-Read-Data-3.2\">3.2 Open and Read Data</a></span></li><li><span><a href=\"#3.3-Split-Dataset\" data-toc-modified-id=\"3.3-Split-Dataset-3.3\">3.3 Split Dataset</a></span></li><li><span><a href=\"#3.4-Create-Models\" data-toc-modified-id=\"3.4-Create-Models-3.4\">3.4 Create Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.4.1-Decision-Tree\" data-toc-modified-id=\"3.4.1-Decision-Tree-3.4.1\">3.4.1 Decision Tree</a></span></li><li><span><a href=\"#3.4.2-Random-Forest\" data-toc-modified-id=\"3.4.2-Random-Forest-3.4.2\">3.4.2 Random Forest</a></span></li><li><span><a href=\"#3.4.3-Logistic-Regression\" data-toc-modified-id=\"3.4.3-Logistic-Regression-3.4.3\">3.4.3 Logistic Regression</a></span></li></ul></li><li><span><a href=\"#3.5-Testing-the-Model\" data-toc-modified-id=\"3.5-Testing-the-Model-3.5\">3.5 Testing the Model</a></span></li><li><span><a href=\"#3.6-Sanity-Check\" data-toc-modified-id=\"3.6-Sanity-Check-3.6\">3.6 Sanity Check</a></span></li></ul></li><li><span><a href=\"#4-Conclusion\" data-toc-modified-id=\"4-Conclusion-4\">4 Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1 Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Megaline, a mobile operator, is unsatisfied with the fact that many of its customers are still using outdated packages. The company aims to develop a model that can analyze consumer behavior and recommend either the Smart or Ultra packages as a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 1.1 Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this project include:\n",
    "- Analyzing the behavior patterns of Megaline customers who have switched to the latest package.\n",
    "- Developing machine learning models to study the behavior of these users.\n",
    "- Utilizing the models to provide suitable package recommendations for customers who have not yet adopted the latest package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 1.2 Stages of Project Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having previously conducted statistical data analysis on Megaline customer data in the Statistical Data Analysis course project, we will now proceed directly to the modeling stage, assuming that the data preprocessing step has been completed.\n",
    "\n",
    "The objective of this classification task is to develop a model that can accurately recommend the appropriate package for Megaline customers who have not yet switched to the latest package.\n",
    "\n",
    "Our goal is to create a model with the highest possible accuracy, with a minimum threshold of 0.75 for accuracy in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build this model, we will utilize the preprocessed data available in the `users_behavior.csv` file.\n",
    "\n",
    "Each observation in the dataset provides monthly behavioral information for a single user, including the following variables:\n",
    "\n",
    "- `—Åalls`: the number of calls made by the user\n",
    "- `minutes`: the total duration of calls in minutes\n",
    "- `messages`: the number of text messages sent by the user\n",
    "- `mb_used`: the amount of internet usage traffic in megabytes (MB)\n",
    "- `is_ultra`: the package subscribed by the user for the current month (Ultra - 1, Smart - 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 3 Creating a Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 3.1 Import All Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import All Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 3.2 Open and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the data\n",
    "df = pd.read_csv('users_behavior.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dataset shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data description\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the general information of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "**Findings:**\n",
    "- The dataset is clean and does not contain any missing values.\n",
    "- There are 5 columns (features) and 3,214 rows (observations) in the dataset.\n",
    "- The median and average values of the data are close to each other, indicating a relatively balanced distribution without significant outliers.\n",
    "- Overall, the dataset provides sufficient information for the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 3.3 Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To meet the requirements of this model, we have a single dataset that needs to be divided into three groups: the `training set`, `validation set`, and `test set`.\n",
    "\n",
    "Following best practices, we will divide the data in a 3:1:1 ratio, allocating 60% of the data to the `training set`, 20% to the `validation set`, and the remaining 20% to the `test set`.\n",
    "\n",
    "Instead of using the `train_test_split()` function from the `scikit-learn` library, which only splits the data into two parts (train and test), we will utilize `numpy` to split the dataset into all three sets simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train, validate, test = \\\n",
    "              np.split(df.sample(frac=1, random_state=42), \n",
    "                       [int(.6*len(df)), int(.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 5)\n",
      "(643, 5)\n",
      "(643, 5)\n"
     ]
    }
   ],
   "source": [
    "# Examine the shape of the dataset\n",
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "All three datasets have been prepared, and now it is time to separate the data into features and targets. Our target variable is the `is_ultra` column, while the remaining columns will serve as the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lang": "in"
   },
   "outputs": [],
   "source": [
    "# Split the 'train' dataset\n",
    "train_features = train.drop(['is_ultra'], axis=1)\n",
    "train_target = train['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'validate' dataset\n",
    "validate_features = validate.drop(['is_ultra'], axis=1)\n",
    "validate_target = validate['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'test' dataset\n",
    "test_features = test.drop(['is_ultra'], axis=1)\n",
    "test_target = test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 3.4 Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create three models: `decision tree`, `random forest`, and `logistic regression`.\n",
    "\n",
    "The training process will involve using the `train_features` and `train_target` datasets. We will then validate the models using the `validate_features` and `validate_target` datasets. Through experimentation, we will explore the models both with and without hyperparameter tuning to identify the one with the highest accuracy.\n",
    "\n",
    "Following the analysis, we will conduct a sanity check to assess the validity and reasonability of the chosen model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "in"
   },
   "source": [
    "#### 3.4.1 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree model includes the hyperparameter `max_depth`, which determines the depth or height of the decision tree. This parameter defines the number of levels the decision tree will analyze, such as two levels, three levels, four levels, and so on. We will test 10 different levels to identify the option with the highest accuracy. Additionally, we will set the hyperparameter `random_state` to 12345 for consistent results.\n",
    "\n",
    "To assess the presence of overfitting or underfitting, we will create two models: one without hyperparameter tuning and one with hyperparameter tuning. This comparison will allow us to evaluate the impact of hyperparameter optimization on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score using train data is: 100.0\n",
      "Model accuracy score using validation data is: 72.78382581648522\n"
     ]
    }
   ],
   "source": [
    "# No hyperparameter tuning\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(train_features, train_target)\n",
    "\n",
    "dt_predict_train = dt_model.predict(train_features)\n",
    "dt_predict_valid = dt_model.predict(validate_features)\n",
    "\n",
    "print(\"Model accuracy score using train data is:\", accuracy_score(train_target, dt_predict_train) * 100)\n",
    "print(\"Model accuracy score using validation data is:\", accuracy_score(validate_target, dt_predict_valid) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The accuracy scores between the two models are significantly different, suggesting the presence of overfitting. Thus, it is advisable to perform hyperparameter tuning to optimize the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : Train data accuracy is 75.4149377593361 and validation data accuracy is 72.31726283048211\n",
      "max_depth = 2 : Train data accuracy is 78.7344398340249 and validation data accuracy is 76.98289269051321\n",
      "max_depth = 3 : Train data accuracy is 79.92738589211619 and validation data accuracy is 78.53810264385692\n",
      "max_depth = 4 : Train data accuracy is 79.9792531120332 and validation data accuracy is 78.53810264385692\n",
      "max_depth = 5 : Train data accuracy is 81.58713692946058 and validation data accuracy is 78.53810264385692\n",
      "max_depth = 6 : Train data accuracy is 82.88381742738589 and validation data accuracy is 78.69362363919129\n",
      "max_depth = 7 : Train data accuracy is 83.97302904564316 and validation data accuracy is 78.0715396578538\n",
      "max_depth = 8 : Train data accuracy is 85.47717842323651 and validation data accuracy is 78.53810264385692\n",
      "max_depth = 9 : Train data accuracy is 86.35892116182573 and validation data accuracy is 79.00466562986003\n",
      "max_depth = 10 : Train data accuracy is 87.65560165975104 and validation data accuracy is 79.16018662519441\n"
     ]
    }
   ],
   "source": [
    "# With hyperparameter tunning\n",
    "for depth in range(1, 11):\n",
    "    dtree_model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    dtree_model.fit(train_features, train_target)\n",
    "    \n",
    "    predict_train = dtree_model.predict(train_features) \n",
    "    predict_valid = dtree_model.predict(validate_features) \n",
    "    \n",
    "    acc_train = accuracy_score(train_target, predict_train) * 100\n",
    "    acc_valid = accuracy_score(validate_target, predict_valid) * 100\n",
    "        \n",
    "    print('max_depth =', depth, ': ', end='')\n",
    "    print(f'Train data accuracy is {acc_train} and validation data accuracy is {acc_valid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We achieved the highest accuracy score of 87.65% for the training data and 79.16% for the validation data when using a `max_depth` of 10 in the decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "In the random forest model, instead of setting the parameter for the depth of a decision tree, we set the parameter for the number of trees using `n_estimators`. We will test different numbers of trees up to a maximum of 100, while keeping the `random_state` parameter the same as before.\n",
    "\n",
    "We will create models without and with hyperparameter tuning to determine the best number of trees for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score using train data is: 100.0\n",
      "Model accuracy score using validation data is: 80.87091757387248\n"
     ]
    }
   ],
   "source": [
    "# No hyperparameter tuning\n",
    "rforest = RandomForestClassifier() \n",
    "rforest.fit(train_features, train_target) \n",
    "\n",
    "rf_predict_train = rforest.predict(train_features)\n",
    "rf_predict_valid = rforest.predict(validate_features)\n",
    "\n",
    "print(\"Model accuracy score using train data is:\", accuracy_score(train_target, rf_predict_train) * 100)\n",
    "print(\"Model accuracy score using validation data is:\", accuracy_score(validate_target, rf_predict_valid) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We have observed a significant accuracy gap in the random forest model, indicating overfitting. To address this issue, we will apply hyperparameter tuning. Based on previous models, we found that setting `max_depth` to 10 yielded the best accuracy. Therefore, in this model, we will focus on tuning the `n_estimators` parameter to find the optimal number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lang": "in",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10 : Train data accuracy is 88.95 and validation data accuracy is 80.25\n",
      "n_estimators = 20 : Train data accuracy is 88.95 and validation data accuracy is 80.56\n",
      "n_estimators = 30 : Train data accuracy is 89.16 and validation data accuracy is 80.72\n",
      "n_estimators = 40 : Train data accuracy is 89.26 and validation data accuracy is 80.09\n",
      "n_estimators = 50 : Train data accuracy is 89.21 and validation data accuracy is 79.78\n",
      "n_estimators = 60 : Train data accuracy is 89.47 and validation data accuracy is 80.09\n",
      "n_estimators = 70 : Train data accuracy is 89.26 and validation data accuracy is 80.25\n",
      "n_estimators = 80 : Train data accuracy is 89.26 and validation data accuracy is 80.56\n",
      "n_estimators = 90 : Train data accuracy is 89.21 and validation data accuracy is 80.25\n",
      "n_estimators = 100 : Train data accuracy is 89.16 and validation data accuracy is 80.25\n"
     ]
    }
   ],
   "source": [
    "# With hyperparameter tunning\n",
    "\n",
    "for est in range(10, 101, 10):\n",
    "    rf_model = RandomForestClassifier(random_state=54321, max_depth=10, n_estimators=est)\n",
    "    rf_model.fit(train_features, train_target) \n",
    "\n",
    "    rf_predict_train_tunning = rf_model.predict(train_features) \n",
    "    rf_predict_valid_tunning = rf_model.predict(validate_features) \n",
    "\n",
    "    acc_train = accuracy_score(train_target, rf_predict_train_tunning) * 100\n",
    "    acc_valid = accuracy_score(validate_target, rf_predict_valid_tunning) * 100\n",
    "\n",
    "    print('n_estimators =', est, ': ', end='')\n",
    "    print(f'Train data accuracy is {acc_train.round(2)} and validation data accuracy is {acc_valid.round(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lang": "in",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy model is at n_estimators 30 = 0.807153965785381\n"
     ]
    }
   ],
   "source": [
    "# Best model\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(10, 101, 10): \n",
    "    rf_model = RandomForestClassifier(random_state=54321, max_depth=10, n_estimators=est) \n",
    "    rf_model.fit(train_features, train_target) \n",
    "    score = rf_model.score(validate_features, validate_target) \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print(\"The best accuracy model is at n_estimators {} = {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Our random forest model yielded the highest accuracy with 30 trees, achieving an accuracy rate of 89.16% for the train data and 80.72% for the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We will proceed with the third model, which is logistic regression. Unlike the previous two models, we do not need to specify the tree depth or number of trees hyperparameters. Instead, we only need to set the `solver` parameter, and in this case, we will use `liblinear`. We will keep the `random_state` parameter as 12345."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model based on training set: 0.7448132780082988\n",
      "Accuracy of logistic regression model based on validation set: 0.7309486780715396\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression model\n",
    "lr_model = LogisticRegression(random_state=54321, solver='liblinear') \n",
    "lr_model.fit(train_features, train_target) \n",
    "score_train = lr_model.score(train_features, train_target) \n",
    "score_valid = lr_model.score(validate_features, validate_target) \n",
    "\n",
    "print(\"Accuracy of logistic regression model based on training set:\", score_train)\n",
    "print(\"Accuracy of logistic regression model based on validation set:\", score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**\n",
    "\n",
    "Based on the accuracy level, the random forest model achieved the highest score of 80.72% when validating the dataset. To obtain this level of accuracy, a model with 30 trees was analyzed.\n",
    "\n",
    "Another alternative, the decision tree model, also achieved a high level of accuracy at 79.16% with just one tree, using the same depth (max_depth). In contrast, the logistic regression model had a lower accuracy of only 70.45%.\n",
    "\n",
    "Considering these findings, we concluded that the random forest model is the best choice. Although it requires more trees compared to the decision tree model, the increase is still manageable and provides a significant improvement in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 3.5 Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Now we will try to test the selected model on the test_feature and test_target datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=30, random_state=54321)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_estimators=30, random_state=54321)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=30, random_state=54321)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final model\n",
    "final_model = RandomForestClassifier(random_state=54321, max_depth=10, n_estimators=30)\n",
    "final_model.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lang": "in"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test_features dataset\n",
    "test_predictions = final_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8102643856920684\n"
     ]
    }
   ],
   "source": [
    "# Let's check the accuracy\n",
    "print('Accuracy score:', accuracy_score(test_target, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Based on the test results, we achieved a higher accuracy value compared to the training results, indicating that the model is performing well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conduct a sanity check and assess the reasonableness of our model, we can examine the balance of the target data and compare it with the accuracy value of our model. If the accuracy value is higher than the level of data imbalance, it suggests that the model is performing well in analyzing the features, despite the data being unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    444\n",
       "1    199\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts the number of Smart (0) vs Ultra (1) on test_target\n",
    "test_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    69.051322\n",
       "1    30.948678\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of users\n",
    "test_target.value_counts() / test_target.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Based on our analysis, we observed that the test_target dataset consists of 69.05% Smart customers, indicating an imbalance in the data distribution.\n",
    "\n",
    "However, our model achieved an accuracy rate of 81.02%, which is approximately 12% higher than the majority class. This indicates that our model was able to effectively analyze the features and make accurate predictions despite the data imbalance.\n",
    "\n",
    "Here are the predicted counts of Smart (0) and Ultra (1) subscribers generated by our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_prediction_df = pd.DataFrame(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    78.693624\n",
       "1    21.306376\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction_df.value_counts() / test_prediction_df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model predicts that 78.69% of the customers in the test dataset can be recommended to purchase the Smart plan. This percentage is indeed higher than the actual value in the test_target dataset.\n",
    "\n",
    "Furthermore, our model also predicts that a significantly larger number of customers can be offered the Smart package compared to the Ultra package. This observation aligns with the distribution in the test_target dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 4 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After evaluating multiple models, including the decision tree and random forest, we have determined that the random forest model outperforms the others in terms of accuracy. This chosen model demonstrates good predictive performance and passes the sanity check process. Overall, it provides reliable predictions with a high level of accuracy.\n",
    "\n",
    "Based on our analysis and the performance of the chosen random forest model, our recommendation for Megaline would be to utilize this model to make package recommendations for their customers. The random forest model has demonstrated a high level of accuracy in predicting customer preferences between the Smart and Ultra packages. \n",
    "\n",
    "By leveraging this model, Megaline can effectively analyze customer behavior and recommend the appropriate package to customers who have not yet switched to the latest package. This approach will enable Megaline to optimize their offerings and cater to individual customer needs, ultimately leading to improved customer satisfaction and potentially higher subscription rates for the recommended package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "in"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "in",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
