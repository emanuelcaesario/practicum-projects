{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# Bank Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1-Project-Description\" data-toc-modified-id=\"1-Project-Description-1\">1 Project Description</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Objectives\" data-toc-modified-id=\"1.1-Objectives-1.1\">1.1 Objectives</a></span></li><li><span><a href=\"#1.2-Stages\" data-toc-modified-id=\"1.2-Stages-1.2\">1.2 Stages</a></span></li></ul></li><li><span><a href=\"#2-Data-Description\" data-toc-modified-id=\"2-Data-Description-2\">2 Data Description</a></span></li><li><span><a href=\"#3-Open-and-Read-the-Data\" data-toc-modified-id=\"3-Open-and-Read-the-Data-3\">3 Open and Read the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Import-All-Libraries\" data-toc-modified-id=\"3.1-Import-All-Libraries-3.1\">3.1 Import All Libraries</a></span></li><li><span><a href=\"#3.2-Open-the-Data\" data-toc-modified-id=\"3.2-Open-the-Data-3.2\">3.2 Open the Data</a></span></li></ul></li><li><span><a href=\"#4-Data-Pre-processing\" data-toc-modified-id=\"4-Data-Pre-processing-4\">4 Data Pre-processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1-Solving-Missing-Values\" data-toc-modified-id=\"4.1-Solving-Missing-Values-4.1\">4.1 Solving Missing Values</a></span></li><li><span><a href=\"#4.2-Removing-Irrelevant-Features\" data-toc-modified-id=\"4.2-Removing-Irrelevant-Features-4.2\">4.2 Removing Irrelevant Features</a></span></li><li><span><a href=\"#4.3-Addressing-Categorical-Features\" data-toc-modified-id=\"4.3-Addressing-Categorical-Features-4.3\">4.3 Addressing Categorical Features</a></span></li><li><span><a href=\"#4.4-Split-the-Dataset\" data-toc-modified-id=\"4.4-Split-the-Dataset-4.4\">4.4 Split the Dataset</a></span></li><li><span><a href=\"#4.5-Scaling-Numerical-Features-with-High-Variation\" data-toc-modified-id=\"4.5-Scaling-Numerical-Features-with-High-Variation-4.5\">4.5 Scaling Numerical Features with High Variation</a></span></li></ul></li><li><span><a href=\"#5-Checking-Class-Balance\" data-toc-modified-id=\"5-Checking-Class-Balance-5\">5 Checking Class Balance</a></span></li><li><span><a href=\"#6-Train-the-Model-Without-Considering-Imbalance\" data-toc-modified-id=\"6-Train-the-Model-Without-Considering-Imbalance-6\">6 Train the Model Without Considering Imbalance</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1-Decision-Tree\" data-toc-modified-id=\"6.1-Decision-Tree-6.1\">6.1 Decision Tree</a></span></li><li><span><a href=\"#6.2-Random-Forest\" data-toc-modified-id=\"6.2-Random-Forest-6.2\">6.2 Random Forest</a></span></li><li><span><a href=\"#6.3-Logistic-Regression\" data-toc-modified-id=\"6.3-Logistic-Regression-6.3\">6.3 Logistic Regression</a></span></li></ul></li><li><span><a href=\"#7-Train-Models-by-Correcting-Class-Imbalance\" data-toc-modified-id=\"7-Train-Models-by-Correcting-Class-Imbalance-7\">7 Train Models by Correcting Class Imbalance</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.1-Class-Weight-Adjustment\" data-toc-modified-id=\"7.1-Class-Weight-Adjustment-7.1\">7.1 Class Weight Adjustment</a></span></li><li><span><a href=\"#7.2-Upsampling\" data-toc-modified-id=\"7.2-Upsampling-7.2\">7.2 Upsampling</a></span></li><li><span><a href=\"#7.3-Downsampling\" data-toc-modified-id=\"7.3-Downsampling-7.3\">7.3 Downsampling</a></span></li><li><span><a href=\"#7.4-Conclusion\" data-toc-modified-id=\"7.4-Conclusion-7.4\">7.4 Conclusion</a></span></li></ul></li><li><span><a href=\"#8-Final-Testing\" data-toc-modified-id=\"8-Final-Testing-8\">8 Final Testing</a></span></li><li><span><a href=\"#9-Conclusion\" data-toc-modified-id=\"9-Conclusion-9\">9 Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 1 Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Bank Beta has been experiencing a decline in customer numbers over time, highlighting the importance of retaining existing customers rather than acquiring new ones. To address this challenge, the bank is seeking accurate prediction models to anticipate customer behavior and proactively mitigate customer churn. By identifying customers with a higher likelihood of leaving the bank, strategic measures can be taken to retain them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 1.1 Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Our objective is to predict the likelihood of customer churn in the banking industry. By utilizing historical data on client behavior and contract terminations, we aim to develop a model that can accurately determine whether a customer is likely to leave the bank in the near future.\n",
    "\n",
    "The primary goal is to achieve a high F1 score of at least 0.59 on the test dataset. Additionally, we will evaluate the model's performance using the AUC-ROC metric and compare it with the F1 scores to gain further insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 1.2 Stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project will encompass several stages:\n",
    "\n",
    "1. Data pre-processing: Downloading and preparing the data for analysis.\n",
    "2. Class balance check: Assessing the distribution of existing classes.\n",
    "3. Model training without considering class imbalance: Training the initial model and analyzing the obtained results.\n",
    "4. Improving model performance by addressing class imbalance: Implementing techniques to address the class imbalance issue.\n",
    "5. Parameter selection using the training set: Fine-tuning the model's parameters based on the training set.\n",
    "6. Training and evaluating different models on the training and validation sets: Experimenting with various models and assessing their performance.\n",
    "7. Identifying the best models: Selecting the models with the highest performance.\n",
    "8. Conducting final tests: Running tests on the selected models to assess their effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 2 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For machine learning training, we will be using the dataset stored in the file `Churn.csv`. This dataset contains the following features and target variable:\n",
    "\n",
    "**Features:**\n",
    "- `RowNumber`: Index of the data string\n",
    "- `CustomerId`: Customer ID\n",
    "- `Surname`: Last name\n",
    "- `CreditScore`: Credit score\n",
    "- `Geography`: Country of residence\n",
    "- `Gender`: Gender\n",
    "- `Age`: Age\n",
    "- `Tenure`: Maturity period for customer fixed deposits (in years)\n",
    "- `Balance`: Account balance\n",
    "- `NumOfProducts`: Number of bank products used by the customer\n",
    "- `HasCrCard`: Whether the customer has a credit card\n",
    "- `IsActiveMember`: Level of customer activity\n",
    "- `EstimatedSalary`: Estimated salary\n",
    "\n",
    "**Target:**\n",
    "- `Exited`: Whether the customer has quit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 3 Open and Read the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 3.1 Import All Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.metrics import roc_auc_score, f1_score \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 3.2 Open the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lang": "in",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open and save data in the df variable\n",
    "df = pd.read_csv('Churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lang": "in",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking the general information of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings:**\n",
    "- The dataset contains 10,000 rows or observations.\n",
    "- The `tenure` column has a significant number of missing values that need to be addressed.\n",
    "- Some features, such as `RowNumber`, `CustomerId`, and `Surname`, are not relevant for the machine learning process and can be removed.\n",
    "- The target variable, `Exited`, is located in the last column and will be separated from the feature columns.\n",
    "- The presence of categorical features, such as `Geography` and `Gender`, can pose challenges for training models using logistic regression. One-Hot Encoding will be applied to convert these categorical features into numeric representations.\n",
    "- Numerical features with wide variation, including `CreditScore`, `Age`, `Tenure`, `Balance`, `NumOfProducts`, and `EstimatedSalary`, will be standardized to ensure a consistent scale for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 4 Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we will proceed with the following steps based on our previous findings:\n",
    "- Address missing values in the dataset.\n",
    "- Remove irrelevant features, such as `RowNumber`, `CustomerId`, and `Surname`.\n",
    "- Convert categorical features, such as `Geography` and `Gender`, into numeric dummy features using One-Hot Encoding.\n",
    "- Standardize numerical features, including `CreditScore`, `Age`, `Tenure`, `Balance`, `NumOfProducts`, and `EstimatedSalary`, to ensure consistent data scaling.\n",
    "- Split the dataset into training, testing, and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 4.1 Solving Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Missing values ​​are only found in the `Tenure` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lang": "in",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0., nan])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique values of `Tenure`\n",
    "df['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "To handle the missing values in the 'Tenure' column, we can fill them with the median value of the column. Since the 'Tenure' column contains a range from 0 to 10, using the median value as a replacement can help maintain the overall distribution and minimize potential bias in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the missing values\n",
    "median = df['Tenure'].median()\n",
    "df['Tenure'] = df['Tenure'].fillna(median).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  1,  8,  7,  4,  6,  3, 10,  5,  9,  0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the result\n",
    "df['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Thus, the missing values ​​are filled in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 4.2 Removing Irrelevant Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The irrelevant features are `RowNumber`, `CustomerId` and `Surname`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing features\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 4.3 Addressing Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The categorical features that need to be changed are `Geography` and `Gender`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique values of `Gender`\n",
    "df['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique values of `Geography`\n",
    "df['Geography'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "To handle the categorical features 'Gender' and 'Geography', which have two and three unique values respectively, we can create dummy features using one-hot encoding. However, to avoid the dummy variable trap, we will drop one of the dummy features from each category using the parameter `drop_first=True`. This ensures that the features remain independent and avoids multicollinearity in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy features using one-hot encoding\n",
    "data = pd.get_dummies(df, drop_first = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 4.4 Split the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "To create separate datasets for training, testing, and validation, we will split the existing dataset. We will allocate 70% of the data for training purposes, while the remaining 15% each will be allocated for validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train, validate, test = \\\n",
    "              np.split(data.sample(frac=1, random_state=12345), \n",
    "                       [int(.7*len(df)), int(.85*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 12)\n",
      "(1500, 12)\n",
      "(1500, 12)\n"
     ]
    }
   ],
   "source": [
    "# Checking the result\n",
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Now that we have our datasets ready, we will separate them into features and target variables. The target variable in this case is the `Exited` column, while the remaining columns will be treated as the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lang": "in"
   },
   "outputs": [],
   "source": [
    "# Split the 'train' dataset\n",
    "features_train = train.drop(['Exited'], axis=1)\n",
    "target_train = train['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'validate' dataset\n",
    "features_valid = validate.drop(['Exited'], axis=1)\n",
    "target_valid = validate['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'test' dataset\n",
    "features_test = test.drop(['Exited'], axis=1)\n",
    "target_test = test['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 4.5 Scaling Numerical Features with High Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "To ensure that our numeric features are on a similar scale and to prevent any potential confusion for the machine learning model, we will perform feature scaling or standardization on the following columns: `CreditScore`, `Age`, `Tenure`, `Balance`, `NumOfProducts`, and `EstimatedSalary`. This will ensure that these features have a consistent range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>-0.104183</td>\n",
       "      <td>0.684058</td>\n",
       "      <td>-0.715697</td>\n",
       "      <td>-1.217598</td>\n",
       "      <td>-0.922862</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964054</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1.102215</td>\n",
       "      <td>-0.944912</td>\n",
       "      <td>1.089145</td>\n",
       "      <td>0.867111</td>\n",
       "      <td>-0.922862</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.408275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8606</th>\n",
       "      <td>1.617769</td>\n",
       "      <td>0.300771</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>-1.217598</td>\n",
       "      <td>0.810910</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.453011</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8885</th>\n",
       "      <td>0.184527</td>\n",
       "      <td>0.588236</td>\n",
       "      <td>-0.354729</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.810910</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>0.504171</td>\n",
       "      <td>-1.040734</td>\n",
       "      <td>0.728177</td>\n",
       "      <td>-1.217598</td>\n",
       "      <td>0.810910</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.362480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "7867    -0.104183  0.684058 -0.715697 -1.217598      -0.922862          1   \n",
       "1402     1.102215 -0.944912  1.089145  0.867111      -0.922862          1   \n",
       "8606     1.617769  0.300771  0.006240 -1.217598       0.810910          1   \n",
       "8885     0.184527  0.588236 -0.354729  0.422028       0.810910          1   \n",
       "6494     0.504171 -1.040734  0.728177 -1.217598       0.810910          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "7867               1         0.964054                  0                1   \n",
       "1402               0        -0.408275                  0                0   \n",
       "8606               1        -0.453011                  0                1   \n",
       "8885               1         1.000964                  0                1   \n",
       "6494               1        -1.362480                  0                0   \n",
       "\n",
       "      Gender_Male  \n",
       "7867            0  \n",
       "1402            1  \n",
       "8606            1  \n",
       "8885            1  \n",
       "6494            1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the result\n",
    "features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Now, the data is ready for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 5 Checking Class Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding with the modeling process, it is important to perform a sanity check by examining the class balance of the target feature. We will analyze the frequency of the \"1\" and \"0\" classes in the target feature using the `value_counts()` method, which counts the occurrences of each unique value in the feature. This will provide insight into the distribution of classes and help ensure the sanity of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: Exited, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking class balance\n",
    "class_frequency = data['Exited'].value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we have is relatively unbalanced, with the majority class (value '0') representing almost 80 percent of the target data. Therefore, to evaluate the performance of our model, we need to consider metrics beyond traditional accuracy. In this case, we will use the F1 score and AUC-ROC accuracy metrics, which are more suitable for dealing with class imbalance. By using these metrics, we can assess the model's ability to accurately classify both the majority and minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 6 Train the Model Without Considering Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to create the model. For the initial modeling, we will proceed without addressing the class imbalance to assess the model's performance. If the model demonstrates satisfactory accuracy and meets the desired level of performance, it can be considered reliable. However, if the accuracy falls short, we will address the class imbalance issue to improve the model's performance.\n",
    "\n",
    "In this analysis, we will employ three classification machine learning models to determine the best fit for our dataset: decision tree, random forest, and logistic regression. By evaluating the performance of these models, we can identify the most suitable approach for our classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fine-tune the hyperparameters of the decision tree model to prevent overfitting. Specifically, we will focus on two hyperparameters: `max_depth`, which determines the height of the decision tree, and `random_state`, which ensures reproducibility by setting a fixed random seed (12345).\n",
    "\n",
    "To assess the model's quality, we will evaluate both the F1 score and the AUC-ROC score. The F1 score compares the predicted results against the actual target values from the validation dataset. Additionally, the roc_auc_score function measures the area under the receiver operating characteristic (ROC) curve, which illustrates the trade-off between true positive rate and false positive rate. To calculate this score, we will use the predict_proba() function to obtain the positive class probability for each observation in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth 1, F1 score data train = 0.00 | F1 score data valid = 0.00 | AUC-ROC score = 0.67\n",
      "Max depth 2, F1 score data train = 0.51 | F1 score data valid = 0.50 | AUC-ROC score = 0.73\n",
      "Max depth 3, F1 score data train = 0.40 | F1 score data valid = 0.37 | AUC-ROC score = 0.77\n",
      "Max depth 4, F1 score data train = 0.52 | F1 score data valid = 0.52 | AUC-ROC score = 0.80\n",
      "Max depth 5, F1 score data train = 0.50 | F1 score data valid = 0.51 | AUC-ROC score = 0.83\n",
      "Max depth 6, F1 score data train = 0.57 | F1 score data valid = 0.55 | AUC-ROC score = 0.84\n",
      "Max depth 7, F1 score data train = 0.62 | F1 score data valid = 0.58 | AUC-ROC score = 0.84\n",
      "Max depth 8, F1 score data train = 0.67 | F1 score data valid = 0.59 | AUC-ROC score = 0.83\n",
      "Max depth 9, F1 score data train = 0.69 | F1 score data valid = 0.59 | AUC-ROC score = 0.82\n",
      "Max depth 10, F1 score data train = 0.74 | F1 score data valid = 0.57 | AUC-ROC score = 0.78\n"
     ]
    }
   ],
   "source": [
    "# Create the decision tree model\n",
    "for i in range(1, 11):     \n",
    "    dt_model = DecisionTreeClassifier(random_state=12345, max_depth=i)\n",
    "    dt_model.fit(features_train, target_train)\n",
    "    dt_pred_train=dt_model.predict(features_train)\n",
    "    dt_pred_valid=dt_model.predict(features_valid)\n",
    "    probabilities_valid = dt_model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    f1_train = f1_score(target_train, dt_pred_train).round(2)\n",
    "    f1_valid = f1_score(target_valid, dt_pred_valid).round(2)\n",
    "    roc_auc = roc_auc_score(target_valid, probabilities_one_valid).round(2)\n",
    "    print('Max depth {}, F1 score data train = {:.2f} | F1 score data valid = {:.2f} | AUC-ROC score = {:.2f}'\\\n",
    "          .format(i, f1_train, f1_valid, roc_auc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing configuration for the decision tree model is achieved with a `max_depth` of 8. This setting results in the highest F1 score (0.59) on the validation data, as well as a relatively high AUC-ROC score of 0.83 (the third highest among the tested configurations). Although there is a noticeable difference in the F1 score between the training and validation data, it remains within a reasonable range, suggesting that the model is not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We will proceed with testing the second model, which is the random forest. In this model, we will adjust the `n_estimators` parameter, which represents the number of trees in the forest. We will test values ranging from 10 to 100 trees. Additionally, we will also explore the `max_depth` parameter within the range of 1 to 10, while keeping the `random_state` parameter fixed at 12345."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=9, n_estimators=40, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "# Create the random forest model\n",
    "rf = []\n",
    "for i in range(1, 11):\n",
    "    for j in range(10, 101, 10):\n",
    "        rf_model = RandomForestClassifier(random_state=12345, max_depth=i, n_estimators=j)\n",
    "        rf_model.fit(features_train, target_train)\n",
    "        rf.append(rf_model)\n",
    "    \n",
    "print(max(rf, key=lambda rf_model: f1_score(rf_model.predict(features_valid), target_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The best performing model for the random forest classifier is achieved with the hyperparameters `max_depth` = 9, `n_estimators` = 40, and `random_state` = 12345.\n",
    "\n",
    "We will now evaluate the F1 score and AUC-ROC score for this model. These metrics will provide insights into the performance and quality of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score train = 0.65 _ F1 score validasi = 0.58 _ AUC-ROC = 0.85\n"
     ]
    }
   ],
   "source": [
    "# Checking the best model\n",
    "best_rf_model = RandomForestClassifier(random_state=12345, max_depth=9, n_estimators=40)\n",
    "best_rf_model.fit(features_train, target_train)\n",
    "best_rf_train = best_rf_model.predict(features_train) \n",
    "best_rf_pred = best_rf_model.predict(features_valid)\n",
    "probabilities_rf_valid=best_rf_model.predict_proba(features_valid)\n",
    "probabilities_rf_one_valid=probabilities_rf_valid[:, 1]\n",
    "print('F1 score train =', f1_score(target_train, best_rf_train).round(2), '_',\\\n",
    "      'F1 score validasi =', f1_score(target_valid, best_rf_pred).round(2), '_', \\\n",
    "      'AUC-ROC =', roc_auc_score(target_valid, probabilities_rf_one_valid).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "With the random forest model, we achieved the best scores with a validation F1 score of 0.58 and an AUC-ROC score of 0.851. Although there is a notable difference between the F1 scores of the train and validation sets, the model's performance is still acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We will now proceed with the third model, which is logistic regression. Unlike the previous two models, logistic regression does not involve hyperparameters related to tree depth or number of trees. Instead, we will specify the `solver` parameter, and in this case, we will use `liblinear`. We will keep the `random_state` parameter set to 12345."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score train = 0.31 __ F1 score validasi = 0.34 __ AUC-ROC = 0.77\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression model\n",
    "lr_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "lr_model.fit(features_train, target_train)\n",
    "lr_valid_train=lr_model.predict(features_train)\n",
    "lr_valid_pred=lr_model.predict(features_valid)\n",
    "probabilities_lr_valid=lr_model.predict_proba(features_valid)\n",
    "probabilities_lr_one_valid=probabilities_lr_valid[:, 1]\n",
    "print('F1 score train =', f1_score(target_train, lr_valid_train).round(2), '__', \\\n",
    "      'F1 score validasi =', f1_score(target_valid, lr_valid_pred).round(2), '__',\\\n",
    "      'AUC-ROC =', roc_auc_score(target_valid, probabilities_lr_one_valid).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The logistic regression model appears to perform worse than the previous two models. The validation F1 score is only 0.34, and the AUC-ROC is 0.77. Although the range between the F1 scores for the training and validation sets is not significant, suggesting that the model is not overfitting, the overall performance is relatively lower compared to the decision tree and random forest models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 7 Train Models by Correcting Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model without improving the dataset's quality, we obtained decent results. The best model achieved an F1 score of 0.58 and an AUC-ROC of 0.85 using the random forest algorithm with hyperparameters (random_state=12345, max_depth=9, n_estimators=40). Therefore, we have decided to proceed with the random forest model.\n",
    "\n",
    "However, considering the imbalance in our dataset, we need to explore methods to improve the data quality by addressing the class imbalance issue. The F1 scores obtained from the model without quality improvement are not sufficiently high. We will attempt to enhance the dataset quality by adjusting class weights and employing upsampling and downsampling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 7.1 Class Weight Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We will balance the class weights with the `class_weight='balanced'` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score train = 0.74 _ F1 score validasi = 0.6 _ AUC-ROC = 0.85\n"
     ]
    }
   ],
   "source": [
    "# Applying the best random forest model by balancing class weight\n",
    "best_rf_model = RandomForestClassifier(random_state=12345, max_depth=9, n_estimators=40, class_weight='balanced')\n",
    "best_rf_model.fit(features_train, target_train)\n",
    "best_rf_train = best_rf_model.predict(features_train) \n",
    "best_rf_pred = best_rf_model.predict(features_valid)\n",
    "probabilities_rf_valid=best_rf_model.predict_proba(features_valid)\n",
    "probabilities_rf_one_valid=probabilities_rf_valid[:, 1]\n",
    "print('F1 score train =', f1_score(target_train, best_rf_train).round(2), '_', \\\n",
    "      'F1 score validasi =', f1_score(target_valid, best_rf_pred).round(2), '_', \\\n",
    "      'AUC-ROC =', roc_auc_score(target_valid, probabilities_rf_one_valid).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We obtained satisfactory F1 and AUC-ROC scores for our models, although there is a noticeable difference between the F1 scores of the training and validation datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will address the class imbalance issue by increasing the number of samples with a target value of '1', which currently represents only 20 percent of the data. We will attempt to upsample the minority class to increase its representation by a factor of three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "lang": "in"
   },
   "outputs": [],
   "source": [
    "# Upsampling\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features_train[target_train == 0]\n",
    "    features_ones = features_train[target_train == 1] \n",
    "    target_zeros = target_train[target_train == 0]\n",
    "    target_ones = target_train[target_train == 1]\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled \n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5605\n",
       "1    4185\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the result\n",
    "target_upsampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The dataset is relatively balanced, we can test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score train = 0.83 _ F1 score validasi = 0.62 _ AUC-ROC = 0.86\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the upsampling dataset\n",
    "best_rf_model = RandomForestClassifier(random_state=12345, max_depth=9, n_estimators=40)\n",
    "best_rf_model.fit(features_upsampled, target_upsampled)\n",
    "best_rf_train = best_rf_model.predict(features_upsampled) \n",
    "best_rf_pred = best_rf_model.predict(features_valid)\n",
    "probabilities_rf_valid=best_rf_model.predict_proba(features_valid)\n",
    "probabilities_rf_one_valid=probabilities_rf_valid[:, 1]\n",
    "print('F1 score train =', f1_score(target_upsampled, best_rf_train).round(2), '_', \\\n",
    "      'F1 score validasi =', f1_score(target_valid, best_rf_pred).round(2), '_', \\\n",
    "      'AUC-ROC =', roc_auc_score(target_valid, probabilities_rf_one_valid).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The upsampling method yielded relatively improved F1 and AUC-ROC scores compared to the class weight adjustment method. However, it is worth noting that the difference between the F1 train and validation scores is quite significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We will decrease the number of samples with a target value of '0' since it accounts for 80 percent of the data. We will randomly remove some samples from observations with a target value of '0' to rebalance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features_train[target_train == 0]\n",
    "    features_ones = features_train[target_train == 1] \n",
    "    target_zeros = target_train[target_train == 0]\n",
    "    target_ones = target_train[target_train == 1]\n",
    "    \n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [target_ones]\n",
    "    )\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    features_train, target_train, 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1682\n",
       "1    1395\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the result\n",
    "target_downsampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score train = 0.86 _ F1 score validasi = 0.58 _ AUC-ROC = 0.84\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the downsampling dataset\n",
    "best_rf_model = RandomForestClassifier(random_state=12345, max_depth=9, n_estimators=40)\n",
    "best_rf_model.fit(features_downsampled, target_downsampled)\n",
    "best_rf_train = best_rf_model.predict(features_downsampled) \n",
    "best_rf_pred = best_rf_model.predict(features_valid)\n",
    "probabilities_rf_valid=best_rf_model.predict_proba(features_valid)\n",
    "probabilities_rf_one_valid=probabilities_rf_valid[:, 1]\n",
    "print('F1 score train =', f1_score(target_downsampled, best_rf_train).round(2), '_', \\\n",
    "      'F1 score validasi =', f1_score(target_valid, best_rf_pred).round(2), '_', \\\n",
    "      'AUC-ROC =', roc_auc_score(target_valid, probabilities_rf_one_valid).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We get lower F1 and AUC-ROC scores than the upsampling method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 7.4 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We observed that the *random forest* model with the upsampling method yielded the highest score. However, there is a notable difference between the F1 train score and the validation score. Nevertheless, the validation F1 score exceeded the minimum threshold of 0.59 required for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 8 Final Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Now it's time to evaluate the performance of our model on the test dataset, which consists of features_test and target_test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "lang": "in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score train = 0.83 _ F1 score test = 0.65 _ AUC-ROC = 0.87\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on test data\n",
    "best_rf_model = RandomForestClassifier(random_state=12345, max_depth=9, n_estimators=40)\n",
    "best_rf_model.fit(features_upsampled, target_upsampled)\n",
    "best_rf_train = best_rf_model.predict(features_upsampled) \n",
    "best_rf_test = best_rf_model.predict(features_test)\n",
    "probabilities_rf_test = best_rf_model.predict_proba(features_test)\n",
    "probabilities_rf_one_test = probabilities_rf_test[:, 1]\n",
    "print('F1 score train =', f1_score(target_upsampled, best_rf_train).round(2), '_', \\\n",
    "      'F1 score test =', f1_score(target_test, best_rf_test).round(2), '_', \\\n",
    "      'AUC-ROC =', roc_auc_score(target_test, probabilities_rf_one_test).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We obtained an F1 score of 0.65 on the test dataset, surpassing the minimum threshold of 0.59 required for this task. This indicates that our model performs well in predicting whether a customer will leave the bank soon or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## 9 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Based on our analysis, we have successfully developed a reliable model for predicting customer churn in the banking industry. The random forest model, with the hyperparameters `random_state` set to 12345, `max_depth` set to 9, and `n_estimators` set to 40, proved to be the best model for this task.\n",
    "\n",
    "When tested on the test dataset, the random forest model achieved an impressive F1 score of 0.656 and an AUC-ROC of 0.87. These scores far exceed the minimum threshold of 0.59 required for this project, indicating the model's effectiveness in accurately predicting customer churn.\n",
    "\n",
    "With the insights gained from this analysis, banks can now proactively identify customers who are at risk of leaving and take appropriate measures to retain them. This predictive model can significantly contribute to improving customer retention strategies and overall business performance in the banking industry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "in"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "in",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
